+++
title = 'Langchain AI'
date = 2025-10-23T15:41:01+08:00
draft = false
slug = "de862c4"
description = ""
summary = ""
tags = [ "æŠ€æœ¯", "å¼€å‘" ]
categories = [ "tech" ]
cover = ""
author = "MapleScraps"

+++

# Langchain AI

##### LangChain æ˜¯ç”¨äºæ„å»ºåŸºäº**å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰\**åº”ç”¨ç¨‹åºçš„\**å¼€æºæ¡†æ¶ï¼ˆFrameworkï¼‰**ã€‚  

##### LangChain æ¡†æ¶ç”±å‡ ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼Œä»¥å®ç°ä¸Šè¿°åŠŸèƒ½ï¼š

1. **Models (æ¨¡å‹)**: å°è£…äº†ä¸ä¸åŒ LLM æä¾›å•†ï¼ˆå¦‚ OpenAI, HugingFaceï¼‰çš„è¿æ¥æ¥å£ã€‚
2. **Prompts (æç¤ºè¯)**: æä¾›äº†ç®¡ç†ã€æ„å»ºå’Œä¼˜åŒ–å‘é€ç»™ LLM çš„æç¤ºè¯çš„å·¥å…·ã€‚
3. **Chains (é“¾)**: å°†å¤šä¸ª LLM è°ƒç”¨å’Œ/æˆ–å…¶ä»–ç»„ä»¶è¿æ¥åœ¨ä¸€èµ·å½¢æˆç«¯åˆ°ç«¯çš„åº”ç”¨ã€‚
4. **Retrieval (æ£€ç´¢)**: ç”¨äºä»å¤–éƒ¨æ•°æ®æºï¼ˆå¦‚å‘é‡æ•°æ®åº“ï¼‰è·å–ç›¸å…³æ–‡æ¡£ï¼Œè¿™æ˜¯ RAG çš„æ ¸å¿ƒã€‚
5. **Agents (ä»£ç†)**: LLM é€šè¿‡ä»£ç†åšå‡ºå†³ç­–ï¼Œé€‰æ‹©è¦ä½¿ç”¨çš„å·¥å…·å’Œæ‰§è¡Œçš„æ­¥éª¤

##### ğŸ’¦ğŸ’¦ğŸ’¦ ä»¥ä¸‹ç¤ºä¾‹æ˜¯å®ç°åˆ©ç”¨ langchain å’Œ äº‘å¹³å° AI æ¨¡å‹åˆ›å»ºçš„ç”Ÿæˆå¼ AI

```py
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import Tongyi

# åˆ›å»ºä¸€ä¸ªå†…å­˜è®°å¿†å¯¹è±¡
memory = ConversationBufferMemory(return_message=True)

def get_respomse(prompt: str, api_key: str):
    model = Tongyi(model="qwen-max", api_key=api_key)
    chain = ConversationChain(llm=model, memory=memory)
    
    # å‘é€ç”¨æˆ·çš„è¯·æ±‚
    response = chain.invoke({"input": prompt})
    return response["response"]

if __name__ == '__main__':
    print(get_response("è¯·ç”¨Pythonè¾“å‡º1-10", api_key))
    
```



