+++
title = 'Langchain Code'
date = 2025-11-01T20:51:57+08:00
draft = false
slug = "bbe7cd1"
description = ""
summary = ""
tags = [ "æŠ€æœ¯", "å¼€å‘" ]
categories = [ "tech" ]
cover = ""
author = "MapleScraps"
+++

# Langchain Code
## ç¡¬ç¼–ç æ–¹å¼
#### æ¼”ç¤ºå¯¹è¯æ¨¡åž‹
> ```python
> # å¯¼å…¥langchainæ¨¡å—
> from langchain_openai import ChatOpenAI
> 
> # é…ç½®å¯¹è¯æ¨¡åž‹
> chat_model = ChatOpenAI(
> 		# å¿…é¡»è¦è®¾ç½®çš„3ä¸ªå‚æ•°
> 		model_name="gpt-4o-mini", # é»˜è®¤ä½¿ç”¨çš„æ˜¯gpt-3.5-turboæ¨¡åž‹
> 		base_url="https://api.openai-proxy.org/v1",
> 		api_key="xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
> )
> 
> # è°ƒç”¨æ¨¡åž‹
> response = chat_model.invoke("ä»€ä¹ˆæ˜¯langchain?")
> 
> # æŸ¥çœ‹å“åº”æ–‡æœ¬
> print(response.content)
> ```

---

#### æ¼”ç¤ºéžå¯¹è¯æ¨¡åž‹
> ```python
> # å¯¼å…¥langchainæ¨¡å—
> from langchain_openai import OpenAI
> 
> # é…ç½®å¯¹è¯æ¨¡åž‹
> llm = OpenAI(
> 		# å¿…é¡»è¦è®¾ç½®çš„3ä¸ªå‚æ•°
> 		# model_name="gpt-4o-mini", # é»˜è®¤ä½¿ç”¨çš„æ˜¯gpt-3.5-turboæ¨¡åž‹
> 		base_url="https://api.openai-proxy.org/v1",
> 		api_key="xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
> )
> 
> # è°ƒç”¨æ¨¡åž‹
> response = llm.invoke("ä»€ä¹ˆæ˜¯langchain?")
> 
> # æŸ¥çœ‹å“åº”æ–‡æœ¬
> print(response)
> ```
> 

---

## çŽ¯å¢ƒå˜é‡æ–¹å¼
#### ä½¿ç”¨ `.env` çš„é…ç½®æ–‡ä»¶
##### åˆ›å»º `.env` æ–‡ä»¶
> ```.env
> OPENAI_API_KEY1="xxxxxxxxxxxxxxxxxxxx"
> OPENAI_BASE_URL="xxxxxxxxxxxxxxxxxxxx"
> 
> # é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°
> DASHSCOPE_APY_KEY="xxxxxxxxxxxxxxxxxx"
> DASHSCOPE_BASE_URL="xxxxxxxxxxxxxxxxxx"
> 
> # æ™ºè°±
> ZHIPUAI_API_KEY="xxxxxxxxxxxxxxxxxxxx"
> ZHIPUAI_URL="xxxxxxxxxxxxxxxxxxxxxxx"
> 
> # ç¡…åŸºæµåŠ¨
> SILICON_API_KEY="xxxxxxxxxxxxxxxxxxxx"
> ```

> ##### ç¤ºä¾‹ä¸€
> ```python
> # å¯¼å…¥langchainæ¨¡å—
> from langchain_openai import ChatOpenAI
> import dotenv
> import os
> 
> # è¯»å–.envæ–‡ä»¶ï¼ˆðŸ’¡ é»˜è®¤æƒ…å†µä¸‹ï¼Œload_dotenv() ä¼šè‡ªåŠ¨åœ¨é¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾ .env æ–‡ä»¶ï¼‰
> dotenv.load_dotenv()
> 
> # é…ç½®å¯¹è¯æ¨¡åž‹
> chat_model = ChatOpenAI(
> 		# å¿…é¡»è¦è®¾ç½®çš„3ä¸ªå‚æ•°
> 		model_name="gpt-4o-mini", # é»˜è®¤ä½¿ç”¨çš„æ˜¯gpt-3.5-turboæ¨¡åž‹
> 		base_url=os.getenv("OPENAI_BASE_URL"),
> 		api_key=os.getenv("OPENAI_API_KEY"),
> )
> 
> # è°ƒç”¨æ¨¡åž‹
> response = chat_model.invoke("ä»€ä¹ˆæ˜¯langchain?")
> 
> # æŸ¥çœ‹å“åº”æ–‡æœ¬
> print(response)
> ```
> 

> ##### ç¤ºä¾‹äºŒ
> ```python
> # å¯¼å…¥langchainæ¨¡å—
> from langchain_openai import ChatOpenAI
> import dotenv
> import os
> 
> # è¯»å–.envæ–‡ä»¶ï¼ˆðŸ’¡ é»˜è®¤æƒ…å†µä¸‹ï¼Œload_dotenv() ä¼šè‡ªåŠ¨åœ¨é¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾ .env æ–‡ä»¶ï¼‰
> dotenv.load_dotenv()
> 
> # è®¾ç½®çŽ¯å¢ƒå˜é‡å€¼
> os.environ["OPENAI_BASE_URL"] = os.getenv("OPENAI_BASE_URL")
> os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY1")
> 
> # é…ç½®å¯¹è¯æ¨¡åž‹
> chat_model = ChatOpenAI(
> 		# å¿…é¡»è¦è®¾ç½®çš„3ä¸ªå‚æ•°
> 		model_name="gpt-4o-mini", # é»˜è®¤ä½¿ç”¨çš„æ˜¯gpt-3.5-turboæ¨¡åž‹
> 		# base_url=os.getenv("OPENAI_BASE_URL"),
> 		# api_key=os.getenv("OPENAI_API_KEY"),
> )
> 
> # è°ƒç”¨æ¨¡åž‹
> response = chat_model.invoke("ä»€ä¹ˆæ˜¯langchain?")
> 
> # æŸ¥çœ‹å“åº”æ–‡æœ¬
> print(response)
> ```
> è¡¥å……ï¼š  
> å½“ `ChatOpenAI( )` å½“æ²¡æœ‰å£°æ˜Ž `base_url` å’Œ `api_key` çš„æ—¶å€™ï¼Œé»˜è®¤ä¼šä»ŽçŽ¯å¢ƒå˜é‡ä¸­æŸ¥æ‰¾  
> å¯ä»¥å‚è€ƒ `ChatOpenAI( )` æ–‡æ¡£   
> 

---

#### å…¶ä»–å‚æ•°è¯´æ˜Ž
> `temperature`ï¼šæŽ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„ ' éšæœºæ€§ 'ï¼Œå–å€¼èŒƒå›´ 0 ~ 1  
>> - å€¼è¶Šä½Ž --> è¾“å‡ºè¶Šç¡®å®šï¼Œä¿å®ˆï¼ˆé€‚åˆäº‹å®žå›žç­”ï¼‰  
>> - å€¼è¶Šé«˜ --> è¾“å‡ºè¶Šå¤šæ ·ï¼Œæœ‰åˆ›æ„ï¼ˆé€‚åˆåˆ›æ„å†™ä½œï¼‰  
>> ##### éœ€æ±‚è®¾ç½®å‚è€ƒï¼š  
>> - ç²¾å‡†æ¨¡å¼ï¼ˆ 0.5 æˆ–æ›´ä½Ž ï¼‰--> ç”Ÿæˆçš„æ–‡æœ¬æ›´åŠ å®‰å…¨å¯é ï¼Œä½†å¯èƒ½ç¼ºä¹åˆ›æ„å’Œå¤šæ ·æ€§  
>> - å¹³è¡¡æ¨¡å¼ï¼ˆ ä¸€èˆ¬æ˜¯ 0.8 ï¼‰ --> ç”Ÿæˆçš„æ–‡æœ¬é€šå¸¸æ—¢æœ‰ä¸€å®šçš„å¤šæ ·æ€§ï¼Œåˆèƒ½ä¿æŒè¾ƒå¥½çš„è¿žè´¯æ€§å’Œå‡†ç¡®æ€§  
>> - åˆ›æ„æ¨¡å¼ï¼ˆ ä¸€èˆ¬æ˜¯ 1 ï¼‰ --> ç”Ÿæˆçš„æ–‡æœ¬æ›´æœ‰åˆ›æ„ï¼Œä½†ä¹Ÿæ›´å®¹æ˜“å‡ºçŽ°è¯­æ³•é”™è¯¯æˆ–ä¸åˆé€»è¾‘çš„å†…å®¹  

> `max_tokens`ï¼šé™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢è¾“å‡ºè¿‡é•¿
>> Token æ˜¯ä»€ä¹ˆï¼Ÿ
>> 